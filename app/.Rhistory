"sentimentr", "gplots", "dplyr",
"tm", "syuzhet", "factoextra",
"beeswarm", "scales", "RColorBrewer",
"RANN", "tm", "topicmodels")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
# load packages
library("rvest")
library("tibble")
library("qdap")
library("sentimentr")
library("gplots")
library("dplyr")
library("tm")
library("syuzhet")
library("factoextra")
library("beeswarm")
library("scales")
library("RColorBrewer")
library("RANN")
library("tm")
library("topicmodels")
#source("../lib/plotstacked.R")
#source("../lib/speechFuncs.R")
# load all files into a Corpus
ff.all<-Corpus(DirSource("../data/InauguralSpeeches"))
# load Inaugration Info
InaugurationInfo <- read_delim("../data/inauglist.csv",delim="\t")
substrRight <- function(x, n){
substr(x, nchar(x)-n+1, nchar(x))
}
InaugurationInfo$Year=substrRight(InaugurationInfo$Date,4)
InaugurationInfo$President_term=paste(InaugurationInfo$File,InaugurationInfo$Term)
# create a table showing presidents and parties:
parties <- unique(InaugurationInfo[,c("File","Party")])
colnames(parties)=c("President","Party")
# select only Republican and Democratic
parties=parties[parties$Party %in% c("Democratic","Republican"),]
ff.all<-tm_map(ff.all, stripWhitespace)
ff.all<-tm_map(ff.all, content_transformer(tolower))
ff.all<-tm_map(ff.all, removeWords, stopwords("english"))
ff.all<-tm_map(ff.all, removeWords, character(0))
ff.all<-tm_map(ff.all, removePunctuation)
myStopwords <- c("can", "say","one","way","use",
"also","howevever","tell","will",
"much","need","take","tend","even",
"like","particular","rather","said",
"get","well","make","ask","come","end",
"first","two","help","often","may",
"might","see","something","thing","point",
"post","look","right","now","think","‘ve ",
"‘re ","another","put","set","new","good",
"want","sure","kind","large","yes,","day","etc",
"quit","since","attempt","lack","seen","awar",
"littl","ever","moreover","though","found",
"enough","far","away","achieve","draw",
"last","never","brief","bit","fellow",
"great","let","upon","help","today","change","methods"
,"happy","journey","millions","together","century","with","but","or","by","be","this","not","that", "we","must","every","â€","shall","time","just","made","years","country","â€"
)
ff.all <- tm_map(ff.all, removeWords, myStopwords)
dtm <- DocumentTermMatrix(ff.all,
control = list(weighting = function(x)
weightTfIdf(x,
normalize =FALSE),
stopwords = TRUE))
ff.dtm=tidy(dtm)
filenames=ff.dtm$document
name_processing=function(filename,pattern){
matches=regexec(pattern = pattern,filename)
result<-regmatches(filename,matches)
president_name=result[[1]][2]
term=result[[1]][3]
return(c(president_name,term))
}
regex="inaug(.*?)-([0-9])\\.txt"
presidentNames=c()
terms=c()
for (filename in filenames){
result=name_processing(filename,pattern=regex)
presidentNames=c(presidentNames,result[1])
terms=c(terms,result[2])
}
President_term=paste(presidentNames,terms)
ff.dtm$President=presidentNames
ff.party=merge(ff.dtm,parties,by='President')
ff.party=summarise(group_by(ff.party, term,Party), sum(count))
Republican=ff.party[ff.party$Party=="Republican",]
Democratic=ff.party[ff.party$Party=="Democratic",]
Republican$RelativeFrequency_Rep=Republican$`sum(count)`/sum(Republican$`sum(count)`)*100
Democratic$RelativeFrequency_Dem=Democratic$`sum(count)`/sum(Democratic$`sum(count)`)*100
# get top 30 words for each party:
Republican.top50=Republican[order(Republican$`sum(count)`,decreasing = TRUE)[1:50],]
Democratic.top50=Democratic[order(Democratic$`sum(count)`,decreasing = TRUE)[1:50],]
temp1=merge(Republican.top50,Democratic,by="term",all.x=TRUE)[,c("term","RelativeFrequency_Rep","RelativeFrequency_Dem")]
temp1[is.na(temp1)]=0
temp2=merge(Republican,Democratic.top50,by="term",all.y=TRUE)[,c("term","RelativeFrequency_Rep","RelativeFrequency_Dem")]
temp2[is.na(temp2)]=0
party_plot=rbind(temp1,temp2)
party_plot=unique(party_plot)
plot_ly(data=party_plot,x=~RelativeFrequency_Rep,y=~RelativeFrequency_Dem,text=~term,hoverinfo="text",mode = "markers") %>%
layout(title = 'Term Ralative Frequency: Republican VS Democracy',
yaxis = list(zeroline=TRUE,range=c(0,0.5),title='Democratic Relative Frequency(%)'),
xaxis = list(zeroline=TRUE,range=c(0,0.5),title='Republcian Relative Frequency(%)'),
shapes=list(type='line',x0=0,x1=1,y0=0,y1=1,line=list(width=1,color="red")),
annotations=list(
list(x=0.25,y=0.25,text="Equal Frequency"),
list(x=0.05,y=0.2,text="Democratic said more!",showarrow=FALSE,
font=list(color='blue',size=15)),
list(x=0.25,y=0.05,text="Republican said more!",showarrow=FALSE,
font=list(color='red',size=15))
)
)
packages.used=c("tm", "wordcloud", "RColorBrewer",
"dplyr", "tidytext","readr","plotly","rvest", "tibble", "qdap",
"sentimentr", "gplots", "dplyr",
"tm", "syuzhet", "factoextra",
"beeswarm", "scales", "RColorBrewer",
"RANN", "tm", "topicmodels")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE,
repos='http://cran.us.r-project.org')
}
library(tm)
library(dplyr)
library(tidytext)
library(readr)
library(plotly)
library(topicmodels)
# load all files into a Corpus
ff.all<-Corpus(DirSource("../data/InauguralSpeeches"))
# load Inaugration Info
InaugurationInfo <- read_delim("../data/inauglist.csv",delim="\t")
substrRight <- function(x, n){
substr(x, nchar(x)-n+1, nchar(x))
}
InaugurationInfo$Year=substrRight(InaugurationInfo$Date,4)
InaugurationInfo$President_term=paste(InaugurationInfo$File,InaugurationInfo$Term)
# create a table showing presidents and parties:
parties <- unique(InaugurationInfo[,c("File","Party")])
colnames(parties)=c("President","Party")
# select only Republican and Democratic
parties=parties[parties$Party %in% c("Democratic","Republican"),]
# load all files into a Corpus
ff.all<-Corpus(DirSource("../data/InauguralSpeeches"))
# load Inaugration Info
InaugurationInfo <- read_delim("../data/inauglist.csv",delim="\t")
substrRight <- function(x, n){
substr(x, nchar(x)-n+1, nchar(x))
}
InaugurationInfo$Year=substrRight(InaugurationInfo$Date,4)
InaugurationInfo$President_term=paste(InaugurationInfo$File,InaugurationInfo$Term)
# create a table showing presidents and parties:
parties <- unique(InaugurationInfo[,c("File","Party")])
colnames(parties)=c("President","Party")
# select only Republican and Democratic
parties=parties[parties$Party %in% c("Democratic","Republican"),]
ff.all<-tm_map(ff.all, stripWhitespace)
ff.all<-tm_map(ff.all, content_transformer(tolower))
ff.all<-tm_map(ff.all, removeWords, stopwords("english"))
ff.all<-tm_map(ff.all, removeWords, character(0))
ff.all<-tm_map(ff.all, removePunctuation)
myStopwords <- c("can", "say","one","way","use",
"also","howevever","tell","will",
"much","need","take","tend","even",
"like","particular","rather","said",
"get","well","make","ask","come","end",
"first","two","help","often","may",
"might","see","something","thing","point",
"post","look","right","now","think","‘ve ",
"‘re ","another","put","set","new","good",
"want","sure","kind","large","yes,","day","etc",
"quit","since","attempt","lack","seen","awar",
"littl","ever","moreover","though","found",
"enough","far","away","achieve","draw",
"last","never","brief","bit","fellow",
"great","let","upon","help","today","change","methods"
,"happy","journey","millions","together","century","with","but","or","by","be","this","not","that", "we","must","every","â€","shall","time","just","made","years","country","â€"
)
ff.all <- tm_map(ff.all, removeWords, myStopwords)
dtm <- DocumentTermMatrix(ff.all,
control = list(weighting = function(x)
weightTfIdf(x,
normalize =FALSE),
stopwords = TRUE))
ff.dtm=tidy(dtm)
filenames=ff.dtm$document
name_processing=function(filename,pattern){
matches=regexec(pattern = pattern,filename)
result<-regmatches(filename,matches)
president_name=result[[1]][2]
term=result[[1]][3]
return(c(president_name,term))
}
regex="inaug(.*?)-([0-9])\\.txt"
presidentNames=c()
terms=c()
for (filename in filenames){
result=name_processing(filename,pattern=regex)
presidentNames=c(presidentNames,result[1])
terms=c(terms,result[2])
}
President_term=paste(presidentNames,terms)
ff.dtm$President=presidentNames
ff.party=merge(ff.dtm,parties,by='President')
ff.party=summarise(group_by(ff.party, term,Party), sum(count))
Republican=ff.party[ff.party$Party=="Republican",]
Democratic=ff.party[ff.party$Party=="Democratic",]
Republican$RelativeFrequency_Rep=Republican$`sum(count)`/sum(Republican$`sum(count)`)*100
Democratic$RelativeFrequency_Dem=Democratic$`sum(count)`/sum(Democratic$`sum(count)`)*100
# get top 30 words for each party:
Republican.top50=Republican[order(Republican$`sum(count)`,decreasing = TRUE)[1:50],]
Democratic.top50=Democratic[order(Democratic$`sum(count)`,decreasing = TRUE)[1:50],]
temp1=merge(Republican.top50,Democratic,by="term",all.x=TRUE)[,c("term","RelativeFrequency_Rep","RelativeFrequency_Dem")]
temp1[is.na(temp1)]=0
temp2=merge(Republican,Democratic.top50,by="term",all.y=TRUE)[,c("term","RelativeFrequency_Rep","RelativeFrequency_Dem")]
temp2[is.na(temp2)]=0
party_plot=rbind(temp1,temp2)
party_plot=unique(party_plot)
plot_ly(data=party_plot,x=~RelativeFrequency_Rep,y=~RelativeFrequency_Dem,text=~term,hoverinfo="text",mode = "markers") %>%
layout(title = 'Term Ralative Frequency: Republican VS Democracy',
yaxis = list(zeroline=TRUE,range=c(0,0.3),title='Democratic Relative Frequency(%)'),
xaxis = list(zeroline=TRUE,range=c(0,0.3),title='Republcian Relative Frequency(%)'),
shapes=list(type='line',x0=0,x1=1,y0=0,y1=1,line=list(width=1,color="red")),
annotations=list(
list(x=0.25,y=0.25,text="Equal Frequency"),
list(x=0.05,y=0.2,text="Democratic said more!",showarrow=FALSE,
font=list(color='blue',size=15)),
list(x=0.25,y=0.05,text="Republican said more!",showarrow=FALSE,
font=list(color='red',size=15))
)
)
ff.dtm$President_term=President_term
x=merge(ff.dtm,InaugurationInfo,by='President_term')
ff.history=x[,c("President_term","term","count","Year")]
rm(x)
ff.history=group_by(ff.history,President_term)%>%mutate(RelativeFrequency=count/sum(count)*100)
Democratic_topics
x=c(rep(1,5),rep(2,3))
x
table(x)
write.table(x, file = "../out/test.csv", append = FALSE, quote = TRUE, sep = " ",
eol = "\n", na = "NA", dec = ".", row.names = TRUE,
col.names = TRUE, qmethod = c("escape", "double"),
fileEncoding = "")
write.table(x, file = "../out/test.csv", append = FALSE, quote = TRUE, sep = " ",
eol = "\n", na = "NA", dec = ".", row.names = TRUE,
col.names = TRUE, qmethod = c("escape", "double"),
fileEncoding = "")
write.csv
x="01/01/2016 12:29:24 AM"
y="01/02/2016 1:35 PM"
difftime(y,x)
strptime(x, "%Y-%m-%d %H:%M:%S")
strptime(x,"%Y-%m-%d %H:%M:%S")
x="01/01/2016 12:29:24"
strptime(x,"%Y-%m-%d %H:%M:%S")
strptime(x,"%m-%d-%Y %H:%M:%S")
strptime(x,"%m/%d/%Y %H:%M:%S")
strptime(y,"%m/%d/%Y %H:%M:%S")
y
y="01/02/2016 1:35"
strptime(y,"%m/%d/%Y %H:%M:%S")
y
x
strptime(x,"%m/%d/%Y %H:%M:%S")
d1=strptime(x,"%m/%d/%Y %H:%M:%S")
strptime(y,"%m/%d/%Y %H:%M:%S")
y
y="01/02/2016 1:35:20"
d2=strptime(y,"%m/%d/%Y %H:%M:%S")
d2
difftime(x,y)
x
y
d1
d2
difftime(y,x)
?difftime
difftime(d1, d2, tz,
units = c("auto", "secs", "mins", "hours",
"days", "weeks"))
difftime(d1, d2,
units = c("auto", "secs", "mins", "hours",
"days", "weeks"))
difftime(d1, d2,
units = c( "hours"))
x="01/01/2016 12:29:24 AM"
strptime(x,"%m/%d/%Y %H:%M:%S %p")
x
difftime(d1, d2,
units = c( "secs"))
?diff
?timediff
?difftime
x="01/01/2016 12:29:24 AM"
strptime(x,"%m/%d/%Y %H:%M:%S %p")
x="01/01/2016 12:29:24 PM"
strptime(x,"%m/%d/%Y %H:%M:%S %p")
x="01/01/2016 1:29:24 PM"
strptime(x,"%m/%d/%Y %H:%M:%S %p")
x="01/01/2016 1:29:24 AM"
strptime(x,"%m/%d/%Y %H:%M:%S %p")
strptime(x,"%m/%d/%Y %l:%M:%S %p")
y="01/01/2016 1:29:24 PM"
strptime(x,"%m/%d/%Y %l:%M:%S %p")
strptime(y,"%m/%d/%Y %l:%M:%S %l")
strptime(y,"%m/%d/%Y %l:%M:%S %p")
y
strptime(y,"%m/%d/%Y %l:%M:%S %p")
y="01/01/2016 12:29:24 AM"
strptime(y,"%m/%d/%Y %l:%M:%S %p")
shiny::runApp('D:/expedia_map')
load("./data/data_shiny.Rdata")
data=data_shiny
load("./data/data_shiny.Rdata")
load("./data/data_shiny.Rdata")
shiny::runApp('D:/programming/workspace/github/Fall2017-project2-grp6/app')
runApp('D:/programming/workspace/github/Fall2017-project2-grp6/app')
runApp('D:/programming/workspace/github/Fall2017-project2-grp6/app')
runApp('D:/programming/workspace/github/Fall2017-project2-grp6/app')
runApp('D:/programming/workspace/github/Fall2017-project2-grp6/app')
runApp('D:/programming/workspace/github/Fall2017-project2-grp6/app')
runApp('D:/programming/workspace/github/Fall2017-project2-grp6/app')
runApp('D:/programming/workspace/github/Fall2017-project2-grp6/app')
runApp('D:/programming/workspace/github/Fall2017-project2-grp6/app')
runApp('D:/programming/workspace/github/Fall2017-project2-grp6/app')
runApp('D:/programming/workspace/github/Fall2017-project2-grp6/app')
runApp('D:/programming/workspace/github/Fall2017-project2-grp6/app')
runApp('D:/programming/workspace/github/Fall2017-project2-grp6/app')
runApp('D:/programming/workspace/github/Fall2017-project2-grp6/app')
runApp('D:/programming/workspace/github/Fall2017-project2-grp6/app')
runApp('D:/programming/workspace/github/Fall2017-project2-grp6/app')
load("../output/markets.RData")
load("../output/restaurant.RData")
load("../output/markets.RData")
load("../output/restaurant.RData")
load("../output/sub.station.RData")
load("../output/bus.stop.RData")
shiny::runApp('D:/programming/workspace/github/Fall2017-project2-grp6/app')
load("../output/markets.RData")
load("../output/restaurant.RData")
load("../output/sub.station.RData")
load("../output/bus.stop.RData")
load("../output/markets.RData")
housing=read.csv("../data/truliaRentPrice/housing_geo.csv",header=TRUE, stringsAsFactors =FALSE)
housing=read.csv("../data/truliaRentPrice/housing_geo.csv",header=TRUE, stringsAsFactors =FALSE)
housing=read.csv("D:/programming/workspace/github/Fall2017-project2-grp6/data/truliaRentPrice/data/truliaRentPrice/housing_geo.csv",header=TRUE, stringsAsFactors =FALSE)
housing=read.csv("D:/programming/workspace/github/Fall2017-project2-grp6/data/truliaRentPrice/data/housing_geo.csv",header=TRUE, stringsAsFactors =FALSE)
markets<- read.csv("../data/markets.csv",header=TRUE, stringsAsFactors =FALSE)
load("../output/markets.RData")
load("../output/markets.RData")
load("../output/restaurant.RData")
load("../output/sub.station.RData")
load("../output/bus.stop.RData")
shiny::runApp('D:/programming/workspace/github/Fall2017-project2-grp6/app')
runApp('D:/programming/workspace/github/Fall2017-project2-grp6/app')
runApp('D:/programming/workspace/github/Fall2017-project2-grp6/app')
runApp('D:/programming/workspace/github/Fall2017-project2-grp6/app')
runApp('D:/programming/workspace/github/Fall2017-project2-grp6/app')
load("../output/housing.RData")
load("../output/bus.stop.RData")
load("../output/housing.RData")
load("../output/housing.RData")
shiny::runApp('D:/programming/workspace/github/Fall2017-project2-grp6/app')
runApp('D:/programming/workspace/github/Fall2017-project2-grp6/app')
runApp('D:/programming/workspace/github/Fall2017-project2-grp6/app')
runApp('D:/programming/workspace/github/Fall2017-project2-grp6/app')
load("../output/markets.RData")
load("../output/restaurant.RData")
load("../output/sub.station.RData")
load("../output/bus.stop.RData")
load("../output/markets.RData")
load("../output/restaurant.RData")
shiny::runApp('D:/programming/workspace/github/Fall2017-project2-grp6/app')
shiny::runApp('D:/programming/workspace/github/Fall2017-project2-grp6/app')
runApp('D:/expedia_map')
runApp('D:/programming/workspace/github/Fall2017-project2-grp6/app')
runApp('D:/programming/workspace/github/Fall2017-project2-grp6/app')
runApp('D:/programming/workspace/github/Fall2017-project2-grp6/app')
load("../output/housing.RData")
load("../output/housing.RData")
load("../output/housing.RData")
load("../output/housing.RData")
setwd("~/")
load("../output/housing.RData")
housing<- read.csv("../data/truliaRentPrice/housing_geo.csv",header=TRUE, stringsAsFactors =FALSE)
load("../output/housing.RData")
library(readr)
housing_geo <- read_csv("D:/programming/workspace/github/Fall2017-project2-grp6/data/truliaRentPrice/housing_geo.csv")
View(housing_geo)
library(readr)
housing_geo <- read_csv("D:/programming/workspace/github/Fall2017-project2-grp6/data/truliaRentPrice/housing_geo.csv")
library(readr)
housing_geo <- read_csv("../data/truliaRentPrice/housing_geo.csv")
load("../output/markets.RData")
shiny::runApp('D:/programming/workspace/github/Fall2017-project2-grp6/app')
runApp('D:/programming/workspace/github/Fall2017-project2-grp6/app')
load("../output/markets.RData")
load("../output/restaurant.RData")
housing<- read_csv("../data/truliaRentPrice/housing_geo.csv",header=TRUE, stringsAsFactors =FALSE)
housing_geo <- read_csv("../data/truliaRentPrice/housing_geo.csv")
setwd("D:/programming/workspace/github/Fall2017-project2-grp6/app")
load("../output/markets.RData")
load("../output/restaurant.RData")
load("../output/sub.station.RData")
load("../output/bus.stop.RData")
load("../output/housing.RData")
setwd()
runApp()
getwd()
dirname(sys.frame(1)$ofile)
getwd()
shiny::runApp()
runApp()
runApp()
runApp()
View(bus.stop)
runApp()
runApp()
View(bus.stop)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
View(housing)
housing$price=substring(",","",housing$price)
housing<- read.csv("../data/truliaRentPrice/housing_geo.csv",header=TRUE, stringsAsFactors =FALSE)
housing<- subset(housing, !is.na(lng))
housing$price=substring(",","",housing$price)
View(housing)
housing<- read.csv("../data/truliaRentPrice/housing_geo.csv",header=TRUE, stringsAsFactors =FALSE)
View(housing)
housing<- subset(housing, !is.na(lng))
housing$price=substring(",","",housing$price)
View(housing)
housing<- read.csv("../data/truliaRentPrice/housing_geo.csv",header=TRUE, stringsAsFactors =FALSE)
housing<- subset(housing, !is.na(lng))
housing$price=substring(housing$price,",","")
?substr
housing<- read.csv("../data/truliaRentPrice/housing_geo.csv",header=TRUE, stringsAsFactors =FALSE)
housing<- subset(housing, !is.na(lng))
housing$price=gsub(",","",housing$price)
View(housing)
housing$price=gsub(",","",housing$price) %>% numeric()
housing$price=gsub(",","",housing$price) %>% as.numeric()
View(housing)
as.numeric()
housing<- read.csv("../data/truliaRentPrice/housing_geo.csv",header=TRUE, stringsAsFactors =FALSE)
housing<- subset(housing, !is.na(lng))
housing$price=as.numeric(gsub(",","",housing$price))
View(housing)
housing<- read.csv("../data/truliaRentPrice/housing_geo.csv",header=TRUE, stringsAsFactors =FALSE)
housing<- subset(housing, !is.na(lng))
housing$price=gsub(",","",housing$price)
View(housing)
price=gsub(",","",housing$price)
as.numeric(price)
sum(is.na(price))
housing<- read.csv("../data/truliaRentPrice/housing_geo.csv",header=TRUE, stringsAsFactors =FALSE)
housing<- subset(housing, !is.na(lng))
price=gsub(",","",housing$price)
price
View(housing)
as.numeric(price)
price=as.numeric(price)
price=as.numeric(price)
housing$price=price
View(housing)
housing$price[!is.na(housing$price),]
housing=housing[!is.na(housing$price),]
View(housing)
save(housing, file="../output/housing.RData")
runApp()
housing$bedrooms>3
min_bedrooms=2
max_badrooms=4
min_bathrooms=2
max_bathrooms=2
max_bathrooms=4
min_rent=2000
max_rent=4000
bedroom_filter=housing$bedrooms>min_bedrooms & housing$bedrooms<max_badrooms
bedroom_filter=bedroom_filter=housing$bedrooms>min_bedrooms & housing$bedrooms<max_badrooms
bathroom_filter=housing$bathrooms>min_bathrooms & housing$bathrooms<max_bathrooms
bathroom_filter=bathroom_filter=housing$bathrooms>min_bathrooms & housing$bathrooms<max_bathrooms
price_filter=housing$price>input$min_rent & housing$price<max_rent
price_filter=price_filter=housing$price>min_rent & housing$price<max_rent
filter=bedroom_filter & bathroom_filter & price_filter
housing[filter,]
bedroom_filter=bedroom_filter=housing$bedrooms>0 & housing$bedrooms<4
filter=bedroom_filter & bathroom_filter & price_filter
filter=bedroom_filter & bathroom_filter & price_filter
housing[filter,]
runApp()
runApp()
runApp()
runApp('D:/pinren_document/CU/semester2/learnshiny/expedia_map')
